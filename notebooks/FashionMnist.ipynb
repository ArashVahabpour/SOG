{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !/home/arash/anaconda3/bin/pip install progressbar2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision.utils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "#%matplotlib inline\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "import itertools\n",
    "import time\n",
    "\n",
    "# from progressbar import progressbar as pb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR DEBUG PURPOSES\n",
    "class Timer:\n",
    "    def __init__(self, msg):\n",
    "        self.msg = msg\n",
    "        \n",
    "    def __enter__(self):\n",
    "        torch.cuda.synchronize()\n",
    "        self.start = time.process_time()\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, *args):\n",
    "        torch.cuda.synchronize()\n",
    "        self.end = time.process_time()\n",
    "        self.interval = self.end - self.start\n",
    "        \n",
    "        print('{}: {:.5f}'.format(self.msg, self.interval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f374e6287d0>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manualSeed = 42\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_gaussian = 8  # size of latent gaussian variable\n",
    "block_size = 2  # size of coordinate search blocks\n",
    "n_rounds = 3  # number of coordinate search rounds \n",
    "\n",
    "# n_b = 0  # size of the latent binary variable\n",
    "# n_o = 0  # size of the latent one-hot variable\n",
    "\n",
    "batch_size = 64  # samples of data distribution at each iteration\n",
    "latent_batch_size = np.power(32, block_size)\n",
    "\n",
    "n_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 28  # desired resized image size\n",
    "nc = 1  # number of image channels\n",
    "# workers = 2  # number of workers for dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "gpu_ids = '2,3'\n",
    "gpu_ids = [int(s) for s in gpu_ids.split(',')]\n",
    "device = torch.device(\"cuda:{}\".format(gpu_ids[0]) if use_cuda else \"cpu\")\n",
    "\n",
    "# if len(gpu_ids) > 0:\n",
    "#     torch.cuda.set_device(gpu_ids[0])\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Should the default pytorch URL may fail, edit the source code of EMNIST function and update the URL\n",
    "# E.g: vim ~/anaconda3/lib/python3.7/site-packages/torchvision/datasets/mnist.py\n",
    "# Correct URL as of Jan 2020: https://cloudstor.aarnet.edu.au/plus/s/ZNmuFiuQTqZlu9W/download\n",
    "\n",
    "\n",
    "\n",
    "dataset_mean, dataset_std = 0.1751, 0.3332\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.FashionMNIST('../data', train=True, download=True,\n",
    "                    transform=transforms.Compose([\n",
    "#                         transforms.Resize(img_size),\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize((dataset_mean,), (dataset_std,))\n",
    "                    ])),\n",
    "    batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "\n",
    "# train_loader = torch.utils.data.DataLoader(\n",
    "#     datasets.MNIST('../data', train=True, download=True,\n",
    "#                    transform=transforms.Compose([\n",
    "#                        transforms.ToTensor(),\n",
    "#                        transforms.Normalize((0.1307,), (0.3081,))\n",
    "#                    ])),\n",
    "#     batch_size=batch_size, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([60000, 1, 28, 28]), tensor(0.1307), tensor(0.3081))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset_mean, dataset_std = 0.1751, 0.3332\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../../data', train=True, download=True,\n",
    "                    transform=transforms.Compose([\n",
    "#                         transforms.Resize(img_size),\n",
    "                        transforms.ToTensor(),\n",
    "#                         transforms.Normalize((dataset_mean,), (dataset_std,))\n",
    "                    ])),\n",
    "    batch_size=100000000, shuffle=True)\n",
    "\n",
    "x = next(iter(train_loader))[0]\n",
    "x.shape, x.mean(), x.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlockCoordinateSearch():\n",
    "    def __init__(self, batch_size, latent_batch_size, n_gaussian, n_rounds, block_size, criterion_no_reduction, device, netG):\n",
    "        \"\"\"\n",
    "        Block coordinate grid search optimizer over the distribution of points \n",
    "        in the latent space.\n",
    "        \n",
    "        Args:\n",
    "            criterion_no_reduction: loss function to compare, and MUST NOT have reduction.\n",
    "        \"\"\"\n",
    "        \n",
    "#         self.m = torch.distributions.multivariate_normal.MultivariateNormal(\n",
    "#             torch.zeros(block_size), \n",
    "#             torch.eye(block_size))\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.latent_batch_size = latent_batch_size\n",
    "        self.n_gaussian = n_gaussian\n",
    "        self.block_size = block_size\n",
    "        \n",
    "        self.n_rounds = n_rounds\n",
    "        \n",
    "#         self.netG = netG\n",
    "        self.criterion_no_reduction = criterion_no_reduction\n",
    "        \n",
    "#         if device.type == 'cuda':\n",
    "#             torch.cuda.set_device(device)\n",
    "#             self.torch = torch.cuda\n",
    "#         else:\n",
    "#             self.torch = torch\n",
    "        self.device = device\n",
    "        self.netG = netG\n",
    "        \n",
    "    def _sample_block(self, old_z, block_idx):\n",
    "        \"\"\"\n",
    "        Takes the best codes and perturbs\n",
    "        \n",
    "        Args:\n",
    "            old_z: batch_size x n_gaussian\n",
    "        Returns:\n",
    "            new_z: batch_size x latent_batch_size x n_gaussian\n",
    "        \"\"\"\n",
    "        \n",
    "#         gaussian_samples = torch.randn(self.batch_size, self.latent_batch_size, self.block_size, device=device)\n",
    "        \n",
    "        new_z = old_z.unsqueeze(1).repeat(1, self.latent_batch_size, 1)\n",
    "        new_z[:, :, block_idx * self.block_size:(block_idx + 1) * self.block_size].normal_()\n",
    "        \n",
    "        return new_z\n",
    "        \n",
    "#     def _row_wise_repeat(mat, n_rep):\n",
    "#         \"\"\"\n",
    "#         pytorch equivalent of numpy.repeat\n",
    "#         \"\"\"\n",
    "#         n_rows = mat.shape[0]\n",
    "#         return mat[np.arange(n_rows).repeat(n_rep), :]  # WARNING: np.repeat has a different functionality from torch.repeat\n",
    "\n",
    "    def optimize(self, real):\n",
    "        \"\"\"\n",
    "        Find the loss between the optimal fake data and the real data.\n",
    "        \n",
    "        Args:\n",
    "            real: batch_size x dim_1 x ... x dim_k\n",
    "            \n",
    "        Returns:\n",
    "            best_z: batch_size x n_gaussian\n",
    "        \"\"\"\n",
    "        for round_idx, block_idx in itertools.product(range(self.n_rounds), range(n_gaussian // block_size)):\n",
    "            if round_idx == block_idx == 0:\n",
    "                best_z = torch.zeros(self.batch_size, self.n_gaussian, device=self.device)\n",
    "#             # batch_size x latent_batch_size x n_gaussian\n",
    "            new_z = self._sample_block(best_z, block_idx)\n",
    "\n",
    "            if True:  # if netG is a deconv network\n",
    "                # (batch_size * latent_batch_size) x n_gaussian x 1 x 1\n",
    "                new_z_r = new_z.reshape(self.batch_size * self.latent_batch_size, self.n_gaussian, 1, 1)\n",
    "            else:\n",
    "                new_z_r = new_z.reshape(self.batch_size * self.latent_batch_size, self.n_gaussian)\n",
    "\n",
    "            # (batch_size * latent_batch_size) x dim_1 x ... x dim_k\n",
    "            torch.cuda.synchronize()\n",
    "            with torch.no_grad():  # no need to store the gradients while searching\n",
    "                fake_all = self.netG(new_z_r)\n",
    "\n",
    "            # batch_size x latent_batch_size x dim_1 x ... x dim_k\n",
    "\n",
    "            all_shape = [self.batch_size, self.latent_batch_size, *real.shape[1:]]\n",
    "\n",
    "            # batch_size x latent_batch_size x dim_1 x ... x dim_k\n",
    "            fake_all = fake_all.reshape(all_shape)\n",
    "            real_all = real.unsqueeze(1).expand(all_shape)\n",
    "\n",
    "            # batch_size x latent_batch_size x dim_1 x ... x dim_k\n",
    "            loss = self.criterion_no_reduction(real_all, fake_all)\n",
    "\n",
    "            # batch_size x latent_batch_size x -1\n",
    "            loss = loss.reshape([*all_shape[:2], -1])\n",
    "\n",
    "            # batch_size x latent_batch_size\n",
    "            loss = loss.mean(dim=2)\n",
    "\n",
    "            # batch_size\n",
    "            _, argmin = loss.min(dim=1)\n",
    "\n",
    "            # new_z: batch_size x latent_batch_size x n_gaussian\n",
    "            # best_idx: batch_size x 1 x n_gaussian\n",
    "            best_idx = argmin[:, None, None].repeat(1, 1, self.n_gaussian)\n",
    "\n",
    "            # batch_size x 1 x n_gaussian\n",
    "            best_z = torch.gather(new_z, 1, best_idx)\n",
    "\n",
    "            # batch_size x n_gaussian\n",
    "            best_z = best_z.squeeze()\n",
    "                                            \n",
    "#         x_train = latent_code_dist.sample(latent_batch_size).to(device)\n",
    "#         y_train = real.repeat(latent_batch_size, 1)\n",
    "        \n",
    "#         y_pred = row_wise_repeat(netG(x_train), batch_size)\n",
    "\n",
    "#         loss_all_modes = loss_fn(y_pred, y_train)\n",
    "        \n",
    "\n",
    "#         # Zero the gradients before running the backward pass.\n",
    "#         optimizer.zero_grad()\n",
    "        \n",
    "#         selective_loss = loss_all_modes.mean(dim=1).reshape(latent_batch_size, batch_size).min(dim=0)[0].sum()\n",
    "  \n",
    "\n",
    "        return best_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # D_in is input dimension;\n",
    "# # H is hidden dimension;\n",
    "# # D_out is output dimension.\n",
    "\n",
    "# D_in, H, D_out = n_gaussian, 100, 28 * 28\n",
    "\n",
    "# netG = torch.nn.Sequential(\n",
    "#     torch.nn.Linear(D_in, H),\n",
    "#     torch.nn.ReLU(),\n",
    "#     torch.nn.Linear(H, H),\n",
    "#     torch.nn.ReLU(),\n",
    "#     torch.nn.Linear(H, H),\n",
    "#     torch.nn.ReLU(),\n",
    "#     torch.nn.Linear(H, D_out),\n",
    "# ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngf = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): Generator(\n",
       "    (main): Sequential(\n",
       "      (0): ConvTranspose2d(8, 256, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "      (6): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (8): ReLU(inplace=True)\n",
       "      (9): ConvTranspose2d(64, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (10): Tanh()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generator Code\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, gpu_ids):\n",
    "        super(Generator, self).__init__()\n",
    "        self.gpu_ids = gpu_ids\n",
    "        self.main = nn.Sequential(\n",
    "            # input is Z, going into a convolution\n",
    "            nn.ConvTranspose2d( n_gaussian, ngf * 4, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*4) x 4 x 4\n",
    "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*2) x 8 x 8\n",
    "            nn.ConvTranspose2d( ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf) x 16 x 16\n",
    "            nn.ConvTranspose2d( ngf, nc, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "            # state size. (nc) x 32 x 32\n",
    "#             nn.ConvTranspose2d( ngf, nc, 4, 2, 1, bias=False),\n",
    "#             nn.Tanh()\n",
    "#             # state size. (nc) x 64 x 64\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        y = self.main(input)\n",
    "        for dim in (2,3):\n",
    "            y = y.narrow(dim, start=2, length=28)\n",
    "        return y\n",
    "    \n",
    "# Create the generator\n",
    "netG = Generator(gpu_ids).to(device)\n",
    "\n",
    "# Handle multi-gpu if desired\n",
    "if (device.type == 'cuda') and (len(gpu_ids) > 1):\n",
    "    netG = nn.DataParallel(netG, gpu_ids)\n",
    "\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "\n",
    "# # Handle multi-gpu if desired\n",
    "# if (device.type == 'cuda') and (ngpu > 1):\n",
    "#     netG = nn.DataParallel(netG, list(range(ngpu)))\n",
    "\n",
    "# Apply the weights_init function to randomly initialize all weights\n",
    "#  to mean=0, stdev=0.2.\n",
    "netG.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(netG.parameters(), betas=(0.5, 0.999))\n",
    "\n",
    "criterion = torch.nn.L1Loss()\n",
    "criterion_no_reduction = torch.nn.L1Loss(reduction='none')\n",
    "\n",
    "bcs = BlockCoordinateSearch(batch_size, latent_batch_size, n_gaussian, n_rounds, block_size, criterion_no_reduction, device, netG)\n",
    "\n",
    "loss_log = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_noise = torch.randn(64, n_gaussian, 1, 1, device=device)\n",
    "img_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: 6.45562\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory (malloc at /pytorch/c10/cuda/CUDACachingAllocator.cpp:260)\nframe #0: c10::Error::Error(c10::SourceLocation, std::string const&) + 0x33 (0x7f374072d193 in /home/arash/.local/lib/python3.7/site-packages/torch/lib/libc10.so)\nframe #1: <unknown function> + 0x1ba1a (0x7f374096ea1a in /home/arash/.local/lib/python3.7/site-packages/torch/lib/libc10_cuda.so)\nframe #2: <unknown function> + 0x1cd5e (0x7f374096fd5e in /home/arash/.local/lib/python3.7/site-packages/torch/lib/libc10_cuda.so)\nframe #3: THCStorage_resize + 0xa3 (0x7f36ee5b16f3 in /home/arash/.local/lib/python3.7/site-packages/torch/lib/libtorch.so)\nframe #4: at::native::empty_strided_cuda(c10::ArrayRef<long>, c10::ArrayRef<long>, c10::TensorOptions const&) + 0x636 (0x7f36efb7f856 in /home/arash/.local/lib/python3.7/site-packages/torch/lib/libtorch.so)\nframe #5: <unknown function> + 0x45bcd2a (0x7f36ee4c2d2a in /home/arash/.local/lib/python3.7/site-packages/torch/lib/libtorch.so)\nframe #6: <unknown function> + 0x1f4fc81 (0x7f36ebe55c81 in /home/arash/.local/lib/python3.7/site-packages/torch/lib/libtorch.so)\nframe #7: <unknown function> + 0x3aadfb0 (0x7f36ed9b3fb0 in /home/arash/.local/lib/python3.7/site-packages/torch/lib/libtorch.so)\nframe #8: <unknown function> + 0x1f4fc81 (0x7f36ebe55c81 in /home/arash/.local/lib/python3.7/site-packages/torch/lib/libtorch.so)\nframe #9: <unknown function> + 0x1cb869e (0x7f36ebbbe69e in /home/arash/.local/lib/python3.7/site-packages/torch/lib/libtorch.so)\nframe #10: at::native::to(at::Tensor const&, c10::TensorOptions const&, bool, bool, c10::optional<c10::MemoryFormat>) + 0x245 (0x7f36ebbbf6f5 in /home/arash/.local/lib/python3.7/site-packages/torch/lib/libtorch.so)\nframe #11: <unknown function> + 0x1ffdb9a (0x7f36ebf03b9a in /home/arash/.local/lib/python3.7/site-packages/torch/lib/libtorch.so)\nframe #12: <unknown function> + 0x3ce3866 (0x7f36edbe9866 in /home/arash/.local/lib/python3.7/site-packages/torch/lib/libtorch.so)\nframe #13: <unknown function> + 0x20485e2 (0x7f36ebf4e5e2 in /home/arash/.local/lib/python3.7/site-packages/torch/lib/libtorch.so)\nframe #14: torch::cuda::scatter(at::Tensor const&, c10::ArrayRef<long>, c10::optional<std::vector<long, std::allocator<long> > > const&, long, c10::optional<std::vector<c10::optional<c10::cuda::CUDAStream>, std::allocator<c10::optional<c10::cuda::CUDAStream> > > > const&) + 0x710 (0x7f36ee8bcf60 in /home/arash/.local/lib/python3.7/site-packages/torch/lib/libtorch.so)\nframe #15: <unknown function> + 0x9de8d3 (0x7f3734e858d3 in /home/arash/.local/lib/python3.7/site-packages/torch/lib/libtorch_python.so)\nframe #16: <unknown function> + 0x295a74 (0x7f373473ca74 in /home/arash/.local/lib/python3.7/site-packages/torch/lib/libtorch_python.so)\nframe #17: _PyMethodDef_RawFastCallKeywords + 0x264 (0x563347dce6e4 in /home/arash/anaconda3/bin/python)\nframe #18: _PyCFunction_FastCallKeywords + 0x21 (0x563347dce801 in /home/arash/anaconda3/bin/python)\nframe #19: _PyEval_EvalFrameDefault + 0x4e8c (0x563347e2a2bc in /home/arash/anaconda3/bin/python)\nframe #20: _PyEval_EvalCodeWithName + 0x2f9 (0x563347d6b4f9 in /home/arash/anaconda3/bin/python)\nframe #21: _PyFunction_FastCallKeywords + 0x325 (0x563347dcd9c5 in /home/arash/anaconda3/bin/python)\nframe #22: _PyEval_EvalFrameDefault + 0x4aa9 (0x563347e29ed9 in /home/arash/anaconda3/bin/python)\nframe #23: _PyFunction_FastCallDict + 0x10b (0x563347d6c50b in /home/arash/anaconda3/bin/python)\nframe #24: THPFunction_apply(_object*, _object*) + 0xa7f (0x7f3734b0e3ef in /home/arash/.local/lib/python3.7/site-packages/torch/lib/libtorch_python.so)\nframe #25: _PyMethodDef_RawFastCallKeywords + 0x1e0 (0x563347dce660 in /home/arash/anaconda3/bin/python)\nframe #26: _PyCFunction_FastCallKeywords + 0x21 (0x563347dce801 in /home/arash/anaconda3/bin/python)\nframe #27: _PyEval_EvalFrameDefault + 0x4e8c (0x563347e2a2bc in /home/arash/anaconda3/bin/python)\nframe #28: _PyEval_EvalCodeWithName + 0xbb9 (0x563347d6bdb9 in /home/arash/anaconda3/bin/python)\nframe #29: _PyFunction_FastCallDict + 0x1d5 (0x563347d6c5d5 in /home/arash/anaconda3/bin/python)\nframe #30: <unknown function> + 0x14fd62 (0x563347da4d62 in /home/arash/anaconda3/bin/python)\nframe #31: PyIter_Next + 0xe (0x563347d7973e in /home/arash/anaconda3/bin/python)\nframe #32: PySequence_Tuple + 0xfb (0x563347db505b in /home/arash/anaconda3/bin/python)\nframe #33: _PyEval_EvalFrameDefault + 0x64a0 (0x563347e2b8d0 in /home/arash/anaconda3/bin/python)\nframe #34: _PyEval_EvalCodeWithName + 0xbb9 (0x563347d6bdb9 in /home/arash/anaconda3/bin/python)\nframe #35: _PyFunction_FastCallKeywords + 0x387 (0x563347dcda27 in /home/arash/anaconda3/bin/python)\nframe #36: _PyEval_EvalFrameDefault + 0x416 (0x563347e25846 in /home/arash/anaconda3/bin/python)\nframe #37: _PyEval_EvalCodeWithName + 0xbb9 (0x563347d6bdb9 in /home/arash/anaconda3/bin/python)\nframe #38: _PyFunction_FastCallKeywords + 0x387 (0x563347dcda27 in /home/arash/anaconda3/bin/python)\nframe #39: _PyEval_EvalFrameDefault + 0x416 (0x563347e25846 in /home/arash/anaconda3/bin/python)\nframe #40: _PyEval_EvalCodeWithName + 0x2f9 (0x563347d6b4f9 in /home/arash/anaconda3/bin/python)\nframe #41: _PyFunction_FastCallKeywords + 0x387 (0x563347dcda27 in /home/arash/anaconda3/bin/python)\nframe #42: _PyEval_EvalFrameDefault + 0x14ce (0x563347e268fe in /home/arash/anaconda3/bin/python)\nframe #43: _PyFunction_FastCallKeywords + 0xfb (0x563347dcd79b in /home/arash/anaconda3/bin/python)\nframe #44: _PyEval_EvalFrameDefault + 0x4aa9 (0x563347e29ed9 in /home/arash/anaconda3/bin/python)\nframe #45: _PyEval_EvalCodeWithName + 0x2f9 (0x563347d6b4f9 in /home/arash/anaconda3/bin/python)\nframe #46: _PyFunction_FastCallDict + 0x1d5 (0x563347d6c5d5 in /home/arash/anaconda3/bin/python)\nframe #47: _PyObject_Call_Prepend + 0x63 (0x563347d83c43 in /home/arash/anaconda3/bin/python)\nframe #48: PyObject_Call + 0x6e (0x563347d7895e in /home/arash/anaconda3/bin/python)\nframe #49: _PyEval_EvalFrameDefault + 0x1e20 (0x563347e27250 in /home/arash/anaconda3/bin/python)\nframe #50: _PyEval_EvalCodeWithName + 0x2f9 (0x563347d6b4f9 in /home/arash/anaconda3/bin/python)\nframe #51: _PyFunction_FastCallDict + 0x1d5 (0x563347d6c5d5 in /home/arash/anaconda3/bin/python)\nframe #52: _PyObject_Call_Prepend + 0x63 (0x563347d83c43 in /home/arash/anaconda3/bin/python)\nframe #53: <unknown function> + 0x17116a (0x563347dc616a in /home/arash/anaconda3/bin/python)\nframe #54: _PyObject_FastCallKeywords + 0x49b (0x563347dced2b in /home/arash/anaconda3/bin/python)\nframe #55: _PyEval_EvalFrameDefault + 0x537e (0x563347e2a7ae in /home/arash/anaconda3/bin/python)\nframe #56: _PyFunction_FastCallKeywords + 0xfb (0x563347dcd79b in /home/arash/anaconda3/bin/python)\nframe #57: _PyEval_EvalFrameDefault + 0x6a0 (0x563347e25ad0 in /home/arash/anaconda3/bin/python)\nframe #58: _PyEval_EvalCodeWithName + 0x2f9 (0x563347d6b4f9 in /home/arash/anaconda3/bin/python)\nframe #59: PyEval_EvalCodeEx + 0x44 (0x563347d6c3c4 in /home/arash/anaconda3/bin/python)\nframe #60: PyEval_EvalCode + 0x1c (0x563347d6c3ec in /home/arash/anaconda3/bin/python)\nframe #61: <unknown function> + 0x1e004d (0x563347e3504d in /home/arash/anaconda3/bin/python)\nframe #62: _PyMethodDef_RawFastCallKeywords + 0xe9 (0x563347dce569 in /home/arash/anaconda3/bin/python)\nframe #63: _PyCFunction_FastCallKeywords + 0x21 (0x563347dce801 in /home/arash/anaconda3/bin/python)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-5b83167f1ebd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbenchmark\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m  \u001b[0;31m# temporary speed-up\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0;31m# batch_size x n_gaussian\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mbest_z\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbcs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbenchmark\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-49-2e3f7bcdf251>\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, real)\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msynchronize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# no need to store the gradients while searching\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m                 \u001b[0mfake_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_z_r\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0;31m# batch_size x latent_batch_size x dim_1 x ... x dim_k\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m                                    \"them on device: {}\".format(self.src_device_obj, t.device))\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(self, inputs, kwargs, device_ids)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mscatter_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/parallel/scatter_gather.py\u001b[0m in \u001b[0;36mscatter_kwargs\u001b[0;34m(inputs, kwargs, target_gpus, dim)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mscatter_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_gpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;34mr\"\"\"Scatter with support for kwargs dictionary\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_gpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_gpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/parallel/scatter_gather.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(inputs, target_gpus, dim)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m# None, clearing the cell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscatter_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mscatter_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/parallel/scatter_gather.py\u001b[0m in \u001b[0;36mscatter_map\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mScatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_gpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscatter_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscatter_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/parallel/scatter_gather.py\u001b[0m in \u001b[0;36mscatter_map\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mscatter_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mScatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_gpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscatter_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/parallel/_functions.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, target_gpus, chunk_sizes, dim, input)\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;31m# Perform CPU to GPU copies in a background stream\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mstreams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_get_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtarget_gpus\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_gpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstreams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0;31m# Synchronize with the copy stream\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstreams\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/cuda/comm.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(tensor, devices, chunk_sizes, dim, streams)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mdevices\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \"\"\"\n\u001b[0;32m--> 147\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_scatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstreams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory (malloc at /pytorch/c10/cuda/CUDACachingAllocator.cpp:260)\nframe #0: c10::Error::Error(c10::SourceLocation, std::string const&) + 0x33 (0x7f374072d193 in /home/arash/.local/lib/python3.7/site-packages/torch/lib/libc10.so)\nframe #1: <unknown function> + 0x1ba1a (0x7f374096ea1a in /home/arash/.local/lib/python3.7/site-packages/torch/lib/libc10_cuda.so)\nframe #2: <unknown function> + 0x1cd5e (0x7f374096fd5e in /home/arash/.local/lib/python3.7/site-packages/torch/lib/libc10_cuda.so)\nframe #3: THCStorage_resize + 0xa3 (0x7f36ee5b16f3 in /home/arash/.local/lib/python3.7/site-packages/torch/lib/libtorch.so)\nframe #4: at::native::empty_strided_cuda(c10::ArrayRef<long>, c10::ArrayRef<long>, c10::TensorOptions const&) + 0x636 (0x7f36efb7f856 in /home/arash/.local/lib/python3.7/site-packages/torch/lib/libtorch.so)\nframe #5: <unknown function> + 0x45bcd2a (0x7f36ee4c2d2a in /home/arash/.local/lib/python3.7/site-packages/torch/lib/libtorch.so)\nframe #6: <unknown function> + 0x1f4fc81 (0x7f36ebe55c81 in /home/arash/.local/lib/python3.7/site-packages/torch/lib/libtorch.so)\nframe #7: <unknown function> + 0x3aadfb0 (0x7f36ed9b3fb0 in /home/arash/.local/lib/python3.7/site-packages/torch/lib/libtorch.so)\nframe #8: <unknown function> + 0x1f4fc81 (0x7f36ebe55c81 in /home/arash/.local/lib/python3.7/site-packages/torch/lib/libtorch.so)\nframe #9: <unknown function> + 0x1cb869e (0x7f36ebbbe69e in /home/arash/.local/lib/python3.7/site-packages/torch/lib/libtorch.so)\nframe #10: at::native::to(at::Tensor const&, c10::TensorOptions const&, bool, bool, c10::optional<c10::MemoryFormat>) + 0x245 (0x7f36ebbbf6f5 in /home/arash/.local/lib/python3.7/site-packages/torch/lib/libtorch.so)\nframe #11: <unknown function> + 0x1ffdb9a (0x7f36ebf03b9a in /home/arash/.local/lib/python3.7/site-packages/torch/lib/libtorch.so)\nframe #12: <unknown function> + 0x3ce3866 (0x7f36edbe9866 in /home/arash/.local/lib/python3.7/site-packages/torch/lib/libtorch.so)\nframe #13: <unknown function> + 0x20485e2 (0x7f36ebf4e5e2 in /home/arash/.local/lib/python3.7/site-packages/torch/lib/libtorch.so)\nframe #14: torch::cuda::scatter(at::Tensor const&, c10::ArrayRef<long>, c10::optional<std::vector<long, std::allocator<long> > > const&, long, c10::optional<std::vector<c10::optional<c10::cuda::CUDAStream>, std::allocator<c10::optional<c10::cuda::CUDAStream> > > > const&) + 0x710 (0x7f36ee8bcf60 in /home/arash/.local/lib/python3.7/site-packages/torch/lib/libtorch.so)\nframe #15: <unknown function> + 0x9de8d3 (0x7f3734e858d3 in /home/arash/.local/lib/python3.7/site-packages/torch/lib/libtorch_python.so)\nframe #16: <unknown function> + 0x295a74 (0x7f373473ca74 in /home/arash/.local/lib/python3.7/site-packages/torch/lib/libtorch_python.so)\nframe #17: _PyMethodDef_RawFastCallKeywords + 0x264 (0x563347dce6e4 in /home/arash/anaconda3/bin/python)\nframe #18: _PyCFunction_FastCallKeywords + 0x21 (0x563347dce801 in /home/arash/anaconda3/bin/python)\nframe #19: _PyEval_EvalFrameDefault + 0x4e8c (0x563347e2a2bc in /home/arash/anaconda3/bin/python)\nframe #20: _PyEval_EvalCodeWithName + 0x2f9 (0x563347d6b4f9 in /home/arash/anaconda3/bin/python)\nframe #21: _PyFunction_FastCallKeywords + 0x325 (0x563347dcd9c5 in /home/arash/anaconda3/bin/python)\nframe #22: _PyEval_EvalFrameDefault + 0x4aa9 (0x563347e29ed9 in /home/arash/anaconda3/bin/python)\nframe #23: _PyFunction_FastCallDict + 0x10b (0x563347d6c50b in /home/arash/anaconda3/bin/python)\nframe #24: THPFunction_apply(_object*, _object*) + 0xa7f (0x7f3734b0e3ef in /home/arash/.local/lib/python3.7/site-packages/torch/lib/libtorch_python.so)\nframe #25: _PyMethodDef_RawFastCallKeywords + 0x1e0 (0x563347dce660 in /home/arash/anaconda3/bin/python)\nframe #26: _PyCFunction_FastCallKeywords + 0x21 (0x563347dce801 in /home/arash/anaconda3/bin/python)\nframe #27: _PyEval_EvalFrameDefault + 0x4e8c (0x563347e2a2bc in /home/arash/anaconda3/bin/python)\nframe #28: _PyEval_EvalCodeWithName + 0xbb9 (0x563347d6bdb9 in /home/arash/anaconda3/bin/python)\nframe #29: _PyFunction_FastCallDict + 0x1d5 (0x563347d6c5d5 in /home/arash/anaconda3/bin/python)\nframe #30: <unknown function> + 0x14fd62 (0x563347da4d62 in /home/arash/anaconda3/bin/python)\nframe #31: PyIter_Next + 0xe (0x563347d7973e in /home/arash/anaconda3/bin/python)\nframe #32: PySequence_Tuple + 0xfb (0x563347db505b in /home/arash/anaconda3/bin/python)\nframe #33: _PyEval_EvalFrameDefault + 0x64a0 (0x563347e2b8d0 in /home/arash/anaconda3/bin/python)\nframe #34: _PyEval_EvalCodeWithName + 0xbb9 (0x563347d6bdb9 in /home/arash/anaconda3/bin/python)\nframe #35: _PyFunction_FastCallKeywords + 0x387 (0x563347dcda27 in /home/arash/anaconda3/bin/python)\nframe #36: _PyEval_EvalFrameDefault + 0x416 (0x563347e25846 in /home/arash/anaconda3/bin/python)\nframe #37: _PyEval_EvalCodeWithName + 0xbb9 (0x563347d6bdb9 in /home/arash/anaconda3/bin/python)\nframe #38: _PyFunction_FastCallKeywords + 0x387 (0x563347dcda27 in /home/arash/anaconda3/bin/python)\nframe #39: _PyEval_EvalFrameDefault + 0x416 (0x563347e25846 in /home/arash/anaconda3/bin/python)\nframe #40: _PyEval_EvalCodeWithName + 0x2f9 (0x563347d6b4f9 in /home/arash/anaconda3/bin/python)\nframe #41: _PyFunction_FastCallKeywords + 0x387 (0x563347dcda27 in /home/arash/anaconda3/bin/python)\nframe #42: _PyEval_EvalFrameDefault + 0x14ce (0x563347e268fe in /home/arash/anaconda3/bin/python)\nframe #43: _PyFunction_FastCallKeywords + 0xfb (0x563347dcd79b in /home/arash/anaconda3/bin/python)\nframe #44: _PyEval_EvalFrameDefault + 0x4aa9 (0x563347e29ed9 in /home/arash/anaconda3/bin/python)\nframe #45: _PyEval_EvalCodeWithName + 0x2f9 (0x563347d6b4f9 in /home/arash/anaconda3/bin/python)\nframe #46: _PyFunction_FastCallDict + 0x1d5 (0x563347d6c5d5 in /home/arash/anaconda3/bin/python)\nframe #47: _PyObject_Call_Prepend + 0x63 (0x563347d83c43 in /home/arash/anaconda3/bin/python)\nframe #48: PyObject_Call + 0x6e (0x563347d7895e in /home/arash/anaconda3/bin/python)\nframe #49: _PyEval_EvalFrameDefault + 0x1e20 (0x563347e27250 in /home/arash/anaconda3/bin/python)\nframe #50: _PyEval_EvalCodeWithName + 0x2f9 (0x563347d6b4f9 in /home/arash/anaconda3/bin/python)\nframe #51: _PyFunction_FastCallDict + 0x1d5 (0x563347d6c5d5 in /home/arash/anaconda3/bin/python)\nframe #52: _PyObject_Call_Prepend + 0x63 (0x563347d83c43 in /home/arash/anaconda3/bin/python)\nframe #53: <unknown function> + 0x17116a (0x563347dc616a in /home/arash/anaconda3/bin/python)\nframe #54: _PyObject_FastCallKeywords + 0x49b (0x563347dced2b in /home/arash/anaconda3/bin/python)\nframe #55: _PyEval_EvalFrameDefault + 0x537e (0x563347e2a7ae in /home/arash/anaconda3/bin/python)\nframe #56: _PyFunction_FastCallKeywords + 0xfb (0x563347dcd79b in /home/arash/anaconda3/bin/python)\nframe #57: _PyEval_EvalFrameDefault + 0x6a0 (0x563347e25ad0 in /home/arash/anaconda3/bin/python)\nframe #58: _PyEval_EvalCodeWithName + 0x2f9 (0x563347d6b4f9 in /home/arash/anaconda3/bin/python)\nframe #59: PyEval_EvalCodeEx + 0x44 (0x563347d6c3c4 in /home/arash/anaconda3/bin/python)\nframe #60: PyEval_EvalCode + 0x1c (0x563347d6c3ec in /home/arash/anaconda3/bin/python)\nframe #61: <unknown function> + 0x1e004d (0x563347e3504d in /home/arash/anaconda3/bin/python)\nframe #62: _PyMethodDef_RawFastCallKeywords + 0xe9 (0x563347dce569 in /home/arash/anaconda3/bin/python)\nframe #63: _PyCFunction_FastCallKeywords + 0x21 (0x563347dce801 in /home/arash/anaconda3/bin/python)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, n_epochs + 1):\n",
    "    current_epoch_losses = []\n",
    "    \n",
    "    for iters, (data, _) in enumerate(train_loader):            \n",
    "        with Timer('Iteration %d'%iters):\n",
    "            # batch_size x dim_1 x ... x dim_k\n",
    "            real = data.to(device)\n",
    "\n",
    "            torch.backends.cudnn.benchmark=True  # temporary speed-up\n",
    "            # batch_size x n_gaussian\n",
    "            best_z = bcs.optimize(real)\n",
    "            torch.backends.cudnn.benchmark=False\n",
    "\n",
    "\n",
    "            if True:\n",
    "                best_z = best_z.reshape(batch_size, n_gaussian, 1, 1)\n",
    "\n",
    "            # batch_size x dim_1 x ... x dim_k\n",
    "            fake = netG(best_z)\n",
    "\n",
    "    #         x_train = latent_code_dist.sample(latent_batch_size).to(device)\n",
    "    #         y_train = real.repeat(latent_batch_size, 1)\n",
    "\n",
    "    #         y_pred = row_wise_repeat(netG(x_train), batch_size)\n",
    "\n",
    "    #         loss_all_modes = loss_fn(y_pred, y_train)\n",
    "\n",
    "            # in case we are predicting images with a fully connected net, we have to give it appropriate width and height!\n",
    "            fake = fake.reshape(real.shape)\n",
    "            loss = criterion(real, fake)\n",
    "            # Zero the gradients before running the backward pass.\n",
    "            optimizer.zero_grad()\n",
    "    #         selective_loss = loss_all_modes.mean(dim=1).reshape(latent_batch_size, batch_size).min(dim=0)[0].sum()\n",
    "            loss.backward()        \n",
    "\n",
    "            current_epoch_losses.append(loss)\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            if iters % 50 == 0:           \n",
    "                with torch.no_grad():\n",
    "                    fake = netG(fixed_noise).detach().cpu()\n",
    "                img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n",
    "\n",
    "                plt.imshow(img_list[-1].numpy().transpose(1,2,0))\n",
    "                plt.show()\n",
    "    \n",
    "    loss_log.append(torch.tensor(current_epoch_losses).mean().detach().numpy())\n",
    "    \n",
    "    if True:  # if epoch % 10 == 0:\n",
    "        print('Epoch: {} / Loss: {:.2f}'.format(epoch, loss_log[-1]) + '\\n' + '=' * 22 + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title('Loss vs Epochs Passed')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.plot(range(len(loss_log)), loss_log)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_width = 8\n",
    "\n",
    "x1 = np.linspace(0.02, 0.98, grid_width)\n",
    "x2 = np.linspace(0.02, 0.98, grid_width)\n",
    "x1, x2 = norm.ppf(x1), norm.ppf(x2)  # apply inverse normal cdf to distribute codes equally across the distribution\n",
    "\n",
    "xv1, xv2 = np.meshgrid(x1, x2)\n",
    "xv1, xv2 = xv1.reshape(-1, 1), xv2.reshape(-1, 1)\n",
    "\n",
    "data = next(iter(train_loader))[0]\n",
    "y_pred = data.cpu()\n",
    "y_pred = y_pred\n",
    "\n",
    "img = torchvision.utils.make_grid(y_pred, nrow=grid_width, padding=2, normalize=True, range=None, scale_each=False, pad_value=0)\n",
    "\n",
    "plt.imshow(np.transpose(img, (1,2,0)))\n",
    "plt.axis('off') \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "import cv2 as cv\n",
    "\n",
    "grid_width = 8\n",
    "\n",
    "if True:\n",
    "    x_test = torch.randn(grid_width * grid_width, n_gaussian, 1, 1, device=device)\n",
    "else:\n",
    "    x_test = torch.randn(grid_width * grid_width, n_gaussian, device=device)\n",
    "\n",
    "y_pred = netG(x_test).detach().cpu().reshape(-1, 1, img_size, img_size)\n",
    "# y_pred = y_pred.transpose(3,2)\n",
    "\n",
    "img = torchvision.utils.make_grid(y_pred, nrow=grid_width, padding=2, normalize=False, range=None, scale_each=False, pad_value=0)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(np.transpose(img, (1,2,0)))\n",
    "plt.axis('off') \n",
    "                            \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "import cv2 as cv\n",
    "\n",
    "grid_width = 4\n",
    "x1 = np.linspace(0.02, 0.98, grid_width)\n",
    "x1 = norm.ppf(x1)\n",
    "\n",
    "xv_list = np.meshgrid(*([x1] * 8))\n",
    "xv_list = [xv.reshape(-1, 1) for xv in xv_list]\n",
    "\n",
    "x_test = torch.from_numpy(np.hstack(xv_list)).float().to(device)\n",
    "\n",
    "y_pred = data.cpu()\n",
    "y_pred = torch.cat([netG(x_test[(128*i):(128*(i+1)),:,None,None]).detach().cpu() for i in range(len(x_test)//128)]).reshape(-1, 1, img_size, img_size)\n",
    "# y_pred = y_pred.transpose(3,2)\n",
    "\n",
    "nrow = int(np.sqrt(len(y_pred)))\n",
    "img = torchvision.utils.make_grid(y_pred, nrow=nrow, padding=2, normalize=False, range=None, scale_each=False, pad_value=0)\n",
    "\n",
    "plt.figure(figsize=(nrow, nrow), dpi=img_size)\n",
    "plt.imshow(np.transpose(img, (1,2,0)))\n",
    "plt.axis('off') \n",
    "                            \n",
    "# plt.show()\n",
    "plt.savefig('./fig.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# like a fedback network while searching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls '/home/arash/Desktop/celeba/img_align_celeba/' | wc -l"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
